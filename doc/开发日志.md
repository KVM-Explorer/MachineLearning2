## 算法测试

### 普通KNN算法
在k=3,采用

```
全部样本准确率为19.444444444444446%

类别0的精确率为13.636363636363635%
类别1的精确率为0%

类别2的精确率为28.57142857142857%

类别0的召回率为27.27272727272727%
类别1的召回率为0.0%
类别2的召回率为36.36363636363637%
```



|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 3                | 0                | 8                |
| 第二类样本 | 12               | 0                | 2                |
| 第三类样本 | 7                | 0                | 4                |



### 线性变换映射算法

```
===============================

全部样本准确率为30.555555555555557%

类别0的精确率为30.555555555555557%
类别1的精确率为0%

类别2的精确率为0%

类别0的召回率为100.0%
类别1的召回率为0.0%
类别2的召回率为0.0%
```



|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 11               | 0                | 0                |
| 第二类样本 | 14               | 0                | 0                |
| 第三类样本 | 11               | 0                | 0                |



### 总结1

线性变换使得算法识别能力变差，大幅度提高了第一类样本的的识别范围导致，二三类样本被误识别为第一类样本。总体正确率却随之从19%提升到30%，现阶段的问题我认为主要处在图像特征的提取方面，后续尝试改进。

找到问题所在，特征距离函数错误的采取了加法运算。

### 普通KNN算法

```
===============================

全部样本准确率为63.888888888888886%

类别0的精确率为66.66666666666666%
类别1的精确率为72.72727272727273%

类别2的精确率为50.0%

类别0的召回率为90.9090909090909%
类别1的召回率为57.14285714285714%
类别2的召回率为45.45454545454545%
```



|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 10               | 1                | 0                |
| 第二类样本 | 1                | 8                | 5                |
| 第三类样本 | 4                | 2                | 5                |

### 线性变换映射算法

```
===============================

全部样本准确率为72.22222222222221%

类别0的精确率为73.33333333333333%
类别1的精确率为81.81818181818183%

类别2的精确率为60.0%

类别0的召回率为100.0%
类别1的召回率为64.28571428571429%
类别2的召回率为54.54545454545454%
```



|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 11               | 0                | 0                |
| 第二类样本 | 1                | 9                | 4                |
| 第三类样本 | 3                | 2                | 6                |

### 总结2

识别正确率大幅度提升基本达到预期的基本水平，其后的线性变换依然保持其性能稳定的基础上提升10个百分点。

## 算法性能调优

### 算法性能调优

- ~~K值的选取——交叉验证实验~~
- ~~度量方式的选择~~
  - ~~距离函数~~
  - ~~线性变换适配~~
- ~~同类样本平均密度  ——特征显著程度~~
- one class识别
- 异常样本剔除

### K值交叉验证

#### 目的

  选出最为适合的模型超参数的取值，然后将超参数的值作用到模型的创建中。

####  思想

  将样本的**训练数据**交叉的拆分出不同的训练集和验证集，使用交叉拆分出不同的训练集和验证集测分别试模型的精准度，然后求出的精准度的均值就是此次交叉验证的结果。将交叉验证作用到不同的超参数中，选取出精准度最高的超参数作为模型创建的超参数即可。

#### 实现思路

1. 将训练数据平均分割成K个等份
2. 使用1份数据作为验证数据，其余作为训练数据
3. 计算验证准确率
4. 使用不同的测试集，重复2、3步骤，直到所有等份都作为过训练数据
5. 对准确率做平均，作为对未知数据预测准确率的估计

#### 实验验证

当对训练集按block_size 进行分块,分成block_num训练块，



| block_size | block_num | best_score | best_k               | img                                                          |
| ---------- | --------- | ---------- | -------------------- | ------------------------------------------------------------ |
| 3          | 27        | 82.14      | 3,4,5,6,10           | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041603300.png" alt="image-20220504160019936" style="zoom:50%;" /> |
| 4          | 20        | 76.19      | 4,6,7,8,9,10         | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041604222.png" alt="image-20220504160426170" style="zoom:50%;" /> |
| 5          | 16        | 94.12      | 6,7.8,9,10           | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041605680.png" alt="image-20220504160503608" style="zoom:50%;" /> |
| 6          | 13        | 92.68      | 3,4,5,6              | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041606249.png" alt="image-20220504160634208" style="zoom:50%;" /> |
| 7          | 11        | 91.67      | 5,6,7,8              | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041607849.png" alt="image-20220504160710810" style="zoom:50%;" /> |
| 8          | 10        | 81.82      | 4,5,6,7,8,9,10       | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041611670.png" alt="image-20220504161121616" style="zoom:50%;" /> |
| 9          | 9         | 80.00      | 1, 2, 3, 4, 8, 9, 10 | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041613620.png" alt="image-20220504161309583" style="zoom:50%;" /> |
| 10         | 8         | 88.89      | 6, 7, 8, 9, 10       | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041612300.png" alt="image-20220504161243253" style="zoom:50%;" /> |
| 11         | 7         | 87.5       | 4,5,6                | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041954697.png" alt="image-20220504195410629" style="zoom:50%;" /> |
| 12         | 6         | 71.43      | 1,2,3,9,10           | <img src="https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041955557.png" alt="image-20220504195523508" style="zoom:50%;" /> |

从准确率和最佳K值的交集出发我们确定K为6，在新的K值下

**普通KNN算法**有如下输出，较原有提高了3个百分点达到了66%的正确率

```
===============================

全部样本准确率为66.66666666666666%

类别0的精确率为68.75%
类别1的精确率为80.0%

类别2的精确率为50.0%

类别0的召回率为100.0%
类别1的召回率为57.14285714285714%
类别2的召回率为45.45454545454545%
[[11, 0, 0], [1, 8, 5], [4, 2, 5]]
```

|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 11               | 0                | 0                |
| 第二类样本 | 1                | 8                | 5                |
| 第三类样本 | 4                | 2                | 5                |

**线性变换后的KNN算法**有如下输出

Loss损失函数

![image-20220504162747120](https://markdown-image-1302476306.cos.ap-nanjing.myqcloud.com/202205041627269.png)

```
===============================
全部样本准确率为69.44444444444444%
===============================
类别0的精确率为68.75%
类别1的精确率为88.88888888888889%
类别2的精确率为54.54545454545454%
===============================
类别0的召回率为100.0%
类别1的召回率为57.14285714285714%
类别2的召回率为54.54545454545454%
[[11, 0, 0], [1, 8, 5], [4, 1, 6]]
```

|            | 识别为第一类样本 | 识别为第二类样本 | 识别为第三类样本 |
| ---------- | ---------------- | ---------------- | ---------------- |
| 第一类样本 | 11               | 0                | 0                |
| 第二类样本 | 1                | 8                | 5                |
| 第三类样本 | 4                | 1                | 6                |

在新的K值下线性变换带来的效果提升明显下降

### 变换下的KNN算法

思考K仅仅发生在Detect阶段，按理来说K并不影响线性变换的训练，为什采用不同的K值训练后的模型在后续的运算中呈现出不一样的结果？

应该和线性变换的初始值有关，初始值为随机数导致每次结果不同,因而效果不稳定，目前最佳效果为k=3时73%的正确率，我认为这是KNN算法和特征提取算法的上限决定的，如果需要进一步提升正确率需要改进特征提取算法或者采用其他的机器学习算法以及部分我们尚未熟知的trick

关于比例系数r的选择,基于k=5

| 0.1    | 0.2    | 0.3    | 0.4    | 0.5    | 0.6    | 0.7   | 0.8    | 0.9    |
| ------ | ------ | ------ | ------ | ------ | ------ | ----- | ------ | ------ |
| 63.89% | 63.89% | 63.89% | 63.89% | 63.89% | 63.89% | 63.89 | 63.89% | 63.89% |

K = 3时

| 0.1  | 0.2  | 0.3  | 0.4    | 0.5    | 0.6    | 0.7    | 0.8    | 0.9    |
| ---- | ---- | ---- | ------ | ------ | ------ | ------ | ------ | ------ |
|      |      |      | 58.33% | 73.33% | 63.89% | 63.89% | 63.89% | 63.89% |

### 度量方式的选择

```
===============================
全部样本准确率为72.22%
===============================
类别0的精确率为71.43%
类别1的精确率为100.00%
类别2的精确率为57.14%
===============================
类别0的召回率为90.91%
类别1的召回率为57.14%
类别2的召回率为72.73%
[[10, 0, 1], [1, 8, 5], [3, 0, 8]]
```

曼哈顿距离在当前的K值下，使得准确率达到了72%

```
===============================
全部样本准确率为36.11%
===============================
无预测为0类别的结果
类别1的精确率为36.36%
类别2的精确率为35.71%
===============================
类别0的召回率为0.00%
类别1的召回率为57.14%
类别2的召回率为45.45%
[[0, 8, 3], [0, 8, 6], [0, 6, 5]]
```

汉明顿距离下在当前K值下，准确率下降到36%

```
===============================
全部样本准确率为66.67%
===============================
类别0的精确率为66.67%
类别1的精确率为80.00%
类别2的精确率为54.55%
===============================
类别0的召回率为90.91%
类别1的召回率为57.14%
类别2的召回率为54.55%
[[10, 1, 0], [1, 8, 5], [4, 1, 6]]
```

在用L无穷范书作为距离下，当前K值准确率为66%

因而欧拉距离、曼哈顿距离或者Loo表现较好

### 同类别特征密度

我们定义同类别特征密度为
$$
density =\frac{1}{\frac{\Sigma^{n}_{1}\Sigma^{n}_{i+1}dis_{ij}}{C^{2}_{n}}}
$$
进而我们经过运算可以得到

```
class 0 density:2.680477618554726
class 1 density:1.909388178010877
class 2 density:1.8558977967924861
```

因而从特征的聚集程度我们可以看出类别0的特征密度大，而类别1,2特征密度小，因而对应类别0其特征更加集中显著更容易表现其特点，而类别1,2相比之下特征更加分散，对于类别特征的反应能力相对较弱，进而其表现效果弱于类别0.我们分类过程中的数据也相应地反应了如上特点，类别0的召回率往往大于90%而类别1,2在平均召回率在50%左右

### one class 识别

在实际应用的过程中，我们常常遇到这种情形，比如在识别病虫害叶子类别的过程中混入了正常叶片提取的特征，但是由于训练类别缺少正常叶片导致误分类的情况one class识别就是解决这种情况，其将需要识别的内容根据特征求解边界，超出边界范围之外的内容认定为其他信息，进而形成了病虫害分类和正常叶片分类。在KNN中由于采用距离作为特征之间的度量信息，因而one class识别相当于求解距离范围的阈值

## 参考资料

[KNN与交叉验证](https://www.jianshu.com/p/21483858fcf6)

[one-class(单分类) kNN(K-Nearest Neighbor)算法Matlab实现](https://blog.csdn.net/qq_31460511/article/details/115422141)
